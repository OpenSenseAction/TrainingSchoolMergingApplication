{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: These exercise notebooks are meant to help you to get started with the exercises. They are meant to be incomplete, so you will have to add some steps yourself (often indicated by the \"...\" in the code). The number of steps that have to be added by the participants progressively increases the further you get with the exercises. If you can't figure it out yourself, no worries, have a look at the [solution](../solutions) folder or ask one of the teachers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "241esEeY06hp"
   },
   "source": [
    "# Read, transform and visualize input data\n",
    "\n",
    "In this example, we show how to use the utility functions for loading the sample datasets and plot the data by using the pysteps visualization tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQxuHiFnGjKg"
   },
   "source": [
    "## Load the example dataset\n",
    "\n",
    "Now that we have initialized the notebook, let's import the example MeteoSwiss dataset using the [load_dataset()](https://pysteps.readthedocs.io/en/latest/generated/pysteps.datasets.load_dataset.html) helper function from the `pysteps.datasets` module. The dataset contains radar-derived rain rates from Switzerland. This time series contains 14 elements (i.e. 1 hour and 10 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xowuxAOhxqyP"
   },
   "outputs": [],
   "source": [
    "from pysteps.datasets import load_dataset\n",
    "precip, metadata, timestep = load_dataset('mch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeNKQh4F74Db"
   },
   "source": [
    "The load_dataset() function returns the following values:\n",
    "\n",
    "* precip: a numpy array with (time, y, x) dimensions\n",
    "* metadata: a dictionary with additional information, see below\n",
    "* timestep: separation between each sample in the time series (minutes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzaYmeVmJj_j"
   },
   "source": [
    "Then we can print the metadata using [pprint](https://docs.python.org/3/library/pprint.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0E_0uMKJhq8",
    "outputId": "2d1b7545-8ad5-4621-ab50-f4c0ffeff925"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YczUIHNtJr9u"
   },
   "source": [
    "This should have printed the following key-value pairs:\n",
    "\n",
    "*   `accutime`: accumulation time (minutes) for computing the quantity contained in the data\n",
    "*   `cartesian_unit`: the distance unit of the geographical coordinates\n",
    "*   `institution`: institution providing the data\n",
    "*   `product`: name of the product\n",
    "*   `projection`: PROJ-compatible projection definition\n",
    "*   `threshold`: the minimum observed value\n",
    "*   `timestamps`: list of timestamps, one for each element in the returned data array\n",
    "*   `transform`: applied transformation to the data values (if any)\n",
    "*   `unit`: the unit of the data\n",
    "*   `x1`: x-coordinate of the lower-left corner of the domain in geographical coordinates\n",
    "*   `x2`: x-coordinate of the upper-right corner of the domain in geographical coordinates\n",
    "*   `xpixelsize`: pixel size in x-direction (meters)\n",
    "*   `y1`: y-coordinate of the lower-left corner of the domain in geographical coordinates\n",
    "*   `y2`: y-coordinate of the upper-right corner of the domain in geographical coordinates\n",
    "*   `yorigin`: 'upper' or 'lower' depending on whether the origin of the coordinate system is in the lower-left or upper-left corner\n",
    "*   `ypixelsize`: pixel size in y-direction (meters)\n",
    "*   `zerovalue`: value corresponding to no precipitation\n",
    "*   `zr_a`: the a-coefficient in the Z(R) relationship Z=a*R^b applied to the data (if representing rain rate)\n",
    "*   `zr_b`: the b-coefficient in the Z(R) relationship Z=a*R^b applied to the data (if representing rain rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset processed in the previous sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define a utility function to read the data and produce the metadata required by pysteps. This is given by us, feel free to keep re-using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "def load_opensense_dataset(filename, rain_variable_name=\"rainfall_amount\", **kwargs):\n",
    "    \"\"\"Load dataset processed in the OpenSense training school.\"\"\"\n",
    "\n",
    "    ds = xr.open_dataset(filename)\n",
    "\n",
    "    data = ds[rain_variable_name].data\n",
    "    timestamps = pd.to_datetime(ds.time.values).to_pydatetime()\n",
    "    timestep = (timestamps[1] - timestamps[0]).total_seconds() / 60\n",
    "\n",
    "    if 'x' not in ds.dims:\n",
    "        xpixelsize = abs(ds.lon[1].values - ds.lon[0].values)\n",
    "    else:\n",
    "        xpixelsize = abs(ds.lon.diff(dim=\"x\").isel(x=0, y=0).item())\n",
    "        \n",
    "    if 'y' not in ds.dims:\n",
    "        ypixelsize = abs(ds.lat[1].values - ds.lat[0].values)\n",
    "    else:\n",
    "        ypixelsize = ds.lat.diff(dim=\"y\").isel(x=0, y=0).item()\n",
    "\n",
    "    metadata = {\n",
    "        'accutime': 15,\n",
    "         'institution': ds.attrs[\"institution\"],\n",
    "         'product': 'AQC',\n",
    "        #  The data is a lon-lat grid, so the projection is EPSG:4326\n",
    "         'projection': 'EPSG:4326',\n",
    "         'cartesian_unit': 'degree',\n",
    "         'threshold': 0,\n",
    "         'timestamps': timestamps,\n",
    "         'transform': None,\n",
    "         'unit': 'mm',\n",
    "         'x1': ds.lon.min().item(),\n",
    "         'x2': ds.lon.max().item(),\n",
    "         'xpixelsize': xpixelsize,\n",
    "         'y1': ds.lat.min().item(),\n",
    "         'y2': ds.lat.max().item(),\n",
    "         'yorigin': 'lower',\n",
    "         'ypixelsize': ypixelsize,\n",
    "         'zerovalue': 0,\n",
    "         'zr_a': 316.0,\n",
    "         'zr_b': 1.5,\n",
    "    }\n",
    "\n",
    "    return data, metadata, timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read an example data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path with the path to the OpenSense dataset\n",
    "filename = ...\n",
    "\n",
    "# Load the dataset using the function\n",
    "precip, metadata, timestep = ...\n",
    "\n",
    "pprint(precip)\n",
    "pprint(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data is in a latitude-longitude grid in degrees. Usually, the data ingested in pysteps should be in a Cartesian in meters. However, in this small domain, we can use the latitude-longitude grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEYLo2-ZI-O4"
   },
   "source": [
    "## Plot the data\n",
    "\n",
    "Next we will use the [plot_precip_field](https://pysteps.readthedocs.io/en/stable/generated/pysteps.visualization.precipfields.plot_precip_field.html#pysteps.visualization.precipfields.plot_precip_field) function from the `pysteps.visualization.precipfields` module to plot the data. Here we plot the first element of the time series in mm/h and take its timestamp from the metadata. The plotting is done for the three colormaps implemented in pysteps (pick a few yourself!). Here we also plot the longitude-latitude lines by supplying the `drawlonlatlines` option in `map_kwargs`. Note that in addition to the no precipitation values (light color), we have the gray region containing NaN values (i.e. those outside the radar domain or not valid measurements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "DK3Sm-fq1Z5A",
    "outputId": "13df632b-dd92-4b3b-9c71-bad8b0f1c4bf"
   },
   "outputs": [],
   "source": [
    "from pysteps.visualization import plot_precip_field\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig = plt.figure(figsize=(6, 10), layout=\"constrained\")\n",
    "# set the title to the timestamp of the last precipitation field\n",
    "plt.suptitle(metadata[\"timestamps\"][0])\n",
    "\n",
    "map_kwargs = {\"drawlonlatlines\": True}\n",
    "\n",
    "# plot the last precipitation field\n",
    "# turn off axis, because it will be overwritten in plot_precip_field\n",
    "ax = fig.add_subplot(311); ax.axis(\"off\")\n",
    "plot_precip_field(\n",
    "    precip[132]*4, # *4 to get mm/h\n",
    "    geodata=metadata,\n",
    "    title=\"pysteps\",\n",
    "    colorscale=\"pysteps\",\n",
    "    map_kwargs=map_kwargs,\n",
    "    units=\"mm/h\",\n",
    "); # the default colormap\n",
    "ax = fig.add_subplot(312); ax.axis(\"off\")\n",
    "plot_precip_field(\n",
    "    precip[132]*4,\n",
    "    geodata=metadata,\n",
    "    title=...,\n",
    "    colorscale=...,\n",
    "    map_kwargs=map_kwargs,\n",
    "    units=\"mm/h\",\n",
    "    ax=ax,\n",
    ");\n",
    "ax = fig.add_subplot(313); ax.axis(\"off\")\n",
    "plot_precip_field(\n",
    "    ...\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of the precipitation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use the last available composite and discard any invalid values\n",
    "valid_precip_values = precip[~np.isnan(precip)]\n",
    "\n",
    "bins = np.linspace(0.1, 2, 20)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(valid_precip_values, bins=bins, log=True, edgecolor='black')\n",
    "plt.autoscale(tight=True, axis='x')\n",
    "plt.xlabel(...) # What do you think that should be plotted on the x-axis?\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1ff4vDh6rlv"
   },
   "source": [
    "## Additional datasets and data processing\n",
    "\n",
    "Next we load the FMI dataset that we will use in the following notebooks. Again, this time series contains 14 elements (i.e. 1 hour and 10 minutes). For computational reasons, we upsample the data by a factor of two, so that the spatial resolution will be 2 km instead of the original 1 km resolution. This is done by using [utils.dimension.aggregate_fields_space](https://pysteps.readthedocs.io/en/stable/generated/pysteps.utils.dimension.aggregate_fields_space.html#pysteps.utils.dimension.aggregate_fields_space). Note that the metadata is also updated so that the spatial extent of the composite does not change, only its spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "HIPVYy3z3dYT",
    "outputId": "d57631ac-7978-405f-fabf-165f20f2fd34"
   },
   "outputs": [],
   "source": [
    "from pysteps.datasets import load_dataset\n",
    "from pysteps.utils.dimension import aggregate_fields_space\n",
    "\n",
    "fig = plt.figure(figsize=(7, 10))\n",
    "ax = fig.add_subplot(111); ax.axis(\"off\")\n",
    "\n",
    "precip_fmi, metadata_fmi, timestep_fmi = load_dataset('fmi')\n",
    "print(f\"Original shape: {precip_fmi.shape}\")\n",
    "\n",
    "# Set the aggregation window to 2*pixel size (km) in the x- and y-directions\n",
    "precip_fmi, metadata_fmi = aggregate_fields_space(\n",
    "    precip_fmi,\n",
    "    metadata_fmi,\n",
    "    (2*metadata_fmi[\"xpixelsize\"], 2*metadata_fmi[\"ypixelsize\"])\n",
    ")\n",
    "print(f\"Shape after upsampling: {precip_fmi.shape}\")\n",
    "\n",
    "pprint(f\"Metadata FMI: {metadata_fmi}\")\n",
    "\n",
    "# Visualize the precipitation field\n",
    "plot_precip_field(\n",
    "    ...,\n",
    "    geodata=...,\n",
    "    title=metadata_fmi[\"timestamps\"][-1],\n",
    "    map_kwargs=map_kwargs,\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, pysteps provides functionality for clipping a smaller subdomain from the original data. This can be done by using [dimension.clip_domain](https://pysteps.readthedocs.io/en/stable/generated/pysteps.utils.dimension.clip_domain.html#pysteps.utils.dimension.clip_domain). In this example, we pick southern Finland from the original radar composite. Again, the metadata is updated as well to reflect the clipped raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysteps.utils.dimension import clip_domain\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111); ax.axis(\"off\")\n",
    "\n",
    "# Set the new spatial extent in the Cartesian coordinates (meters)\n",
    "precip_clipped, metadata_clipped = clip_domain(\n",
    "    precip_fmi[-1],\n",
    "    ...,\n",
    "    extent=(metadata_fmi[\"x1\"], metadata_fmi[\"x2\"], 100000, 500000)\n",
    ")\n",
    "plot_precip_field(\n",
    "    ...\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then see what the distribution of the FMI rain rate values looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "QoE1rP4qom78",
    "outputId": "537cc669-ead0-4222-fdd2-1472f15fe737"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use the last available composite and discard any invalid values\n",
    "valid_precip_values = precip_fmi[-1][~np.isnan(precip_fmi[-1])]\n",
    "\n",
    "bins = np.linspace(0.1, 18, 20)\n",
    "\n",
    "# Plot it here, good luck!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyA42RmHpqut"
   },
   "source": [
    "The histogram shows that precipitation rate values have a non-Gaussian and asymmetric distribution that is bounded at zero. Also, the probability of occurrence decays extremely fast with increasing precipitation rate values (note the logarithmic y-axis). This can cause issues when estimating the motion field or applying the nowcasting methods.\n",
    "\n",
    "For the above reason, we can convert the precipitation rate values (in mm/h) to a more symmetric distribution by applying the following logarithmic transformation:\n",
    "\n",
    "\\begin{equation}\n",
    "R\\rightarrow\n",
    "\\begin{cases}\n",
    "    10\\log_{10}R, & \\text{if } R\\geq 0.1\\text{mm h$^{-1}$} \\\\\n",
    "    -15,          & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "The transformed values correspond to logarithmic precipitation rates in units of dBR. The value of −15 dBR is equivalent to assigning a precipitation rate of approximately 0.03 mm h$^{−1}$ to the zeros. This can be done by using the `dB_transform` method in the [transformation](https://pysteps.readthedocs.io/en/stable/pysteps_reference/utils.html#pysteps-utils-transformation) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyMP-JJ2qoDg"
   },
   "outputs": [],
   "source": [
    "from pysteps.utils import transformation\n",
    "\n",
    "# Log-transform the data to dBR with threshold of 0.1 mm/h and fill value of\n",
    "# -15 dBR\n",
    "precip_dbr, metadata_dbr = transformation.dB_transform(\n",
    "    ...,\n",
    "    ...,\n",
    "    threshold=0.1,\n",
    "    zerovalue=-15.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmb_ZJm8q6tB"
   },
   "source": [
    "Let's again plot the distribution of the data after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "S6YFdpjiq57n",
    "outputId": "ee7a66c3-e7e5-4dec-b14a-2756009cc9f6"
   },
   "outputs": [],
   "source": [
    "valid_precip_values = ...\n",
    "\n",
    "bins = np.linspace(-10, 10, 25)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPTzBO-otcHK"
   },
   "source": [
    "In principle, the above should resemble the normal distribution. However, the left side of the distribution is closer to uniform due to the low accuracy of radar observations in this range (i.e. low signal-to-noise ratio) and the limited numerical accuracy of the storage format of the FMI data. If we want to have normally distributed data, it's better to apply the normal quantile transformation [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Ks3Kk1hpXvyx",
    "outputId": "157c3218-dcb4-4039-fc64-5fda1203ccf1"
   },
   "outputs": [],
   "source": [
    "# Apply the normal quantile transformation.\n",
    "# NOTE: It's essential that zero values are not included here. They skew the\n",
    "# original distribution so that the transformated data is not normally\n",
    "# distributed.\n",
    "precip_nq, metadata_nq = transformation.NQ_transform(\n",
    "    precip[-1][precip[-1] > 0],\n",
    "    metadata,\n",
    ")\n",
    "\n",
    "valid_precip_values = precip_nq[np.logical_and(~np.isnan(precip_nq), np.abs(precip_nq) > 0)]\n",
    "\n",
    "bins = np.linspace(-3, 3, 30)\n",
    "\n",
    "# Plot it again\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Vg720QzhxyC"
   },
   "source": [
    "Finally, the following example shows how to transform the data to different units by using the [conversion](https://pysteps.readthedocs.io/en/stable/pysteps_reference/utils.html#pysteps-utils-conversion) module. Here we convert precipitation rate (mm/h) to reflectivity (dBZ) by using the `to_reflectivity` function and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "SqBj_pgZfEPf",
    "outputId": "72516d73-9188-43ad-a7e2-8f6b77b130d5"
   },
   "outputs": [],
   "source": [
    "from pysteps.utils import conversion\n",
    "\n",
    "fig = plt.figure(figsize=(7, 10))\n",
    "ax = fig.add_subplot(111); ax.axis(\"off\")\n",
    "\n",
    "# Convert precipitation rate to reflectivity\n",
    "precip_reflectivity, metadata_reflectivity = conversion.to_reflectivity(precip_fmi[-1], metadata_fmi)\n",
    "\n",
    "# Plot the reflectivity field. Since the data is now in dBZ units, we need to\n",
    "# explicitly specify this when calling plot_precip_field.\n",
    "plot_precip_field(\n",
    "    ...,\n",
    "    geodata=...,\n",
    "    title=metadata_fmi[\"timestamps\"][-1],\n",
    "    units=..., # What are the units?\n",
    "    map_kwargs=map_kwargs,\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H10xWdW_cvEu"
   },
   "source": [
    "## References\n",
    "\n",
    "[1] K. Bogner, F. Pappenberger and H. L. Cloke. Technical Note: The normal quantile transformation and its application in a flood forecasting system, Hydrol. Earth Syst. Sci., 16, 1085-1094, https://doi.org/10.5194/hess-16-1085-2012, 2012."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "opensense_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
